\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Problem 7.9}{1}}
\@writefile{toc}{\contentsline {paragraph}{\fontsize  {10pt}{14pt}\selectfont  \CJKfamily {yahei}Generate a bivariate normal sample of 20 cases with parameter\\ $\mu _1=\mu _2=0$ , $\sigma _{11}=\sigma _{12}=1,\sigma _{22}=2$, denoted $Y_1,Y_2$, and delete values of $Y_2$ so that $Pr(y_2 \ missing | y_1,y_2)$ equals 0.2 if $y_1 < 0$ and 0.8 if $y_1 > 0$. }{1}}
\@writefile{toc}{\contentsline {paragraph}{\fontsize  {10pt}{14pt}\selectfont  \CJKfamily {yahei}Label Description\\ obs\ : cases that both $Y_1$ and $Y_2$ are observed\\ mis\ : cases that $Y_1$ is observed but $Y_2$ is missing\\ S.D. : significant difference }{1}}
\@writefile{toc}{\contentsline {paragraph}{\fontsize  {10pt}{14pt}\selectfont  \CJKfamily {yahei}(a) Construct a test for whether the data are MCAR and carry out the test on the dataset. \\ If the missing-data mechanism is MCAR, there will be no significant difference between $Y_1(obs)$ and $Y_1(mis)$. However, the sample size is small, Repeated trial is needed. I generate 1000 datasets(denoted 7.9-datasets) as the problem describes and carry out t-tests between $Y_1(obs)$ and $Y_1(mis)$ on every one of them. If the p-value of the test is lower than 0.05, it is considered that there is significant difference between $Y_1(obs)$ and $Y_1(mis)$ in the dataset. To tell whether the missing data mechanism is MCAR, I generate another 1000 datasets(denoted MCAR-datasets) that delete 50\% values of $Y_2$ completely at random and carry out t-tests as the same and compare the result of 7.9-datasets and MCAR-datasets. \\ As Table 1\hbox {} shows, more than 60\% of the 7.9-datasets have significant difference between $Y_1(obs)$ and $Y_1(mis)$. However, most of the MCAR-datasets don't have significant difference between $Y_1(obs)$ and $Y_1(mis)$. Therefore, The missing-data mechanism is no MCAR. }{1}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces number of datasets with or without significant difference}}{1}}
\newlabel{tab1}{{1}{1}}
\@writefile{toc}{\contentsline {paragraph}{\fontsize  {10pt}{14pt}\selectfont  \CJKfamily {yahei}(b) Compute 95\% confidence intervals for $\mu _2$ using (i) the data before values were deleted; (ii) the complete cases; (iii) the t-approximation in (2) of Table7.2; Summarize the propeties of these intervals for this missing-data mechanism.\\ (i) Using the data before values were deleted: $\mu _2$ is estimated by the sample mean and $var(\mathaccentV {hat}75E{\mu }_2-\mu _2)$ is estimated by (7.13). The confidence interval is given by (7.15) That is:}{2}}
\newlabel{eq1}{{1}{2}}
\@writefile{toc}{\contentsline {paragraph}{\fontsize  {10pt}{14pt}\selectfont  \CJKfamily {yahei}(ii) Using the complete cases: $\mu _2$ is estimated by the observed-sample mean and $var(\mathaccentV {hat}75E{\mu }_2-\mu _2)$ is estimated by (7.13). except substituting $y$ in equation 1\hbox {} with $y(obs)$ , the procedure to obtain confidence interval is the same as (i).\\ (iii) Using t-approximation in (2) of Table 7.2 : $\mu _2$ is estimated by $\mathaccentV {bar}716{y}_2 + \beta _{211}(\mathaccentV {hat}75E{\mu }_1-\mathaccentV {bar}716{y}_1)$ and $var(\mathaccentV {hat}75E{\mu }_2-\mu _2)$ is estimated by (7.13). intervals are obtain using the complete-case degrees of freedom, the normal percentile 1.96 in equation 1\hbox {} is replaced by the 97.5th percentile of the t distribution.\\ the average confidence intervals obtain by (i)(ii)(iii) is list on Tab 2\hbox {}. We can see that the CIs obtain in (i)(iii) are unbiased while those obtain in (ii) are badly biased. Obviously, the bigger values have bigger chance to be deleted. CIs obtain in (ii) is shorter in length than those obtain in (iii),however the real parameter rarely falls in the CIs obtain in (ii). }{2}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces number of datasets with or without significant difference}}{2}}
\newlabel{tab2}{{2}{2}}
